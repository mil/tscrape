#!/bin/sh
# update feeds, merge with old feeds.
# NOTE: assumes "tscrape_*" executables are in $PATH.

# defaults
tscrapepath="$HOME/.tscrape/feeds"

# used for processing feeds concurrently: wait until ${maxjobs} amount of
# feeds are finished at a time.
maxjobs=8

# load config (evaluate shellscript).
# loadconfig(configfile)
loadconfig() {
	# allow to specify config via argv[1].
	if [ "$1" != "" ]; then
		# get absolute path of config file.
		config=$(readlink -f "$1")
	else
		# default config location.
		config="$HOME/.tscrape/tscraperc"
	fi

	# config is loaded here to be able to override $tscrapepath or functions.
	if [ -r "${config}" ]; then
		. "${config}"
	else
		echo "Configuration file \"${config}\" does not exist or is not readable." >&2
		echo "See tscraperc.example for an example." >&2
		exit 1
	fi
}

# merge raw files: unique sort by id, retweetid.
# merge(name, oldfile, newfile)
merge() {
	sort -t '	' -u -k5,5 -k8,8 "$2" "$3" 2>/dev/null
}

# filter fields.
# filter(name)
filter() {
	cat
}

# order by timestamp (descending).
# order(name)
order() {
	sort -t '	' -k1rn,1
}

# fetch a feed via HTTP/HTTPS etc.
# fetchfeed(name, url, feedfile)
fetchfeed() {
	if curl --http1.0 -L --max-redirs 0 -H "User-Agent:" -f -s -m 15 \
		-z "$3" "$2" 2>/dev/null; then
		printf "  OK %s %s\n" "$(date +'%H:%M:%S')" "$1" >&2
	else
		printf "FAIL %s %s\n" "$(date +'%H:%M:%S')" "$1" >&2
	fi
}

# fetch and parse feed.
# feed(name, feedurl)
feed() {
	# wait until ${maxjobs} are finished: throughput using this logic is
	# non-optimal, but it is simple and portable.
	[ ${signo} -ne 0 ] && return
	[ $((curjobs % maxjobs)) -eq 0 ] && wait
	[ ${signo} -ne 0 ] && return
	curjobs=$((curjobs + 1))

	(name="$1"
	filename="$(printf '%s' "$1" | tr '/' '_')"
	feedurl="$2"
	tmpfeedfile="${tscrapetmpdir}/${filename}"
	tmpencfile=""
	tscrapefile="${tscrapepath}/${filename}"

	fetchfeed "${name}" "${feedurl}" "${tscrapefile}" | \
		tscrape | filter "${name}" > "${tmpfeedfile}"

	# get new data and merge with old.
	tscrapefilenew="${tscrapepath}/${filename}.new"
	# new feed data is non-empty.
	if [ -s "${tmpfeedfile}" ]; then
		# if file exists, merge
		if [ -e "${tscrapefile}" ]; then
			merge "${name}" "${tscrapefile}" "${tmpfeedfile}" | \
				order "${name}" > "${tscrapefilenew}"

			# overwrite old file with updated file
			mv "${tscrapefilenew}" "${tscrapefile}"
		else
			merge "${name}" "/dev/null" "${tmpfeedfile}" | \
				order "${name}" > "${tscrapefile}"
		fi
	fi) &
}

terminated() {
	isrunning="0"
}

cleanup() {
	# remove temporary files
	rm -rf "${tscrapetmpdir}"
}

sighandler() {
	signo="$1"
	# ignore TERM signal for myself.
	trap -- "" TERM
	# kill all running childs >:D
	kill -TERM -$$
}

feeds() {
	echo "Configuration file \"${config}\" is invalid or does not contain a \"feeds\" function." >&2
	echo "See tscraperc.example for an example." >&2
}

# job counter.
curjobs=0
# signal number received for parent.
signo=0
# SIGINT: signal to interrupt parent.
trap -- "sighandler 2" "INT"
# SIGTERM: signal to terminate parent.
trap -- "sighandler 15" "TERM"
# load config file.
loadconfig "$1"
# fetch feeds and store in temporary directory.
tscrapetmpdir="$(mktemp -d '/tmp/tscrape_XXXXXX')"
# make sure path exists.
mkdir -p "${tscrapepath}"
# fetch feeds specified in config file.
feeds
# wait till all feeds are fetched (concurrently).
[ ${signo} -eq 0 ] && wait
# cleanup temporary files etc.
cleanup
# on signal SIGINT and SIGTERM exit with signal number + 128.
[ ${signo} -ne 0 ] && exit $((signo+128))
exit 0
